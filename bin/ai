#!/usr/bin/env bun
// AI-powered bash command generator using OpenAI or Anthropic.

import { $ } from "bun";
import { parseArgs } from "util";

// Parse command line arguments
const { values, positionals } = parseArgs({
  args: Bun.argv.slice(2),
  options: {
    model: {
      type: "string",
      short: "m",
      default: "gpt-5-nano",
    },
    reasoning: {
      type: "string",
      short: "r",
    },
    execute: {
      type: "boolean",
      short: "e",
    },
    help: {
      type: "boolean",
      short: "h",
    },
  },
  allowPositionals: true,
});

// Show help
if (values.help || positionals.length === 0) {
  console.log(`Usage: ai [options] "command description"

AI-powered bash command generator

Options:
  -m, --model <model>      AI model to use (default: gpt-5-nano)
                           OpenAI: gpt-5, gpt-5-mini, gpt-5-nano
                           Anthropic: claude-opus-4-1, claude-opus-4, claude-sonnet-4
  -r, --reasoning <level>  Reasoning level for GPT-5 models (optional)
                           Options: minimal, low, medium, high
  -e, --execute           Execute the command immediately
  -h, --help              Show this help message

Examples:
  ai "show me a tree output but only of .zig files in this repo that aren't gitignored"
  ai -m claude-opus-4-1 "find all TypeScript files larger than 100 lines"
  ai -r high "complex bash script to analyze git history"
  ai -e "list all python files"  # Executes the command immediately

Note: To have the command ready in your prompt (Fish shell), create an alias:
  function ai-prompt
    set cmd (ai $argv)
    commandline -r $cmd
    commandline -f repaint
  end`);
  process.exit(0);
}

const prompt = positionals.join(" ");
const model = values.model as string;

// Determine which API to use based on model name
const isAnthropic = model.toLowerCase().includes("claude");
const isGPT5Model = model.toLowerCase().startsWith("gpt-5");

// System prompt for command generation
const systemPrompt = `You are a bash command generator. Given a natural language description, output ONLY the bash command that accomplishes the task. No explanations, no markdown, just the raw command.

Rules:
- Output only the command itself
- Use common Unix tools when appropriate
- Prefer one-liners when possible
- Use pipes and command substitution as needed
- For file searches, prefer ripgrep (rg) over grep when available
- For directory trees, use tree command with appropriate filters`;

async function getOpenAICommand(apiKey: string): Promise<string> {
  // Map short names to full model names
  const modelMap: Record<string, string> = {
    "gpt-5": "gpt-5-2025-08-07",
    "gpt-5-mini": "gpt-5-mini-2025-08-07",
    "gpt-5-nano": "gpt-5-nano-2025-08-07",
  };

  const fullModel = modelMap[model] || model;

  // GPT-5 models use reasoning levels
  const messages = [
    { role: "system" as const, content: systemPrompt },
    { role: "user" as const, content: prompt },
  ];

  const requestBody: any = {
    model: fullModel,
    messages,
  };

  // GPT-5 has different parameter requirements
  if (isGPT5Model) {
    requestBody.max_completion_tokens = 10000; // Allow plenty of room for reasoning + output
    // Only add reasoning_level if explicitly provided
    if (values.reasoning) {
      requestBody.reasoning_level = values.reasoning;
    }
    // GPT-5 only supports temperature=1 (default)
  } else {
    requestBody.max_tokens = 200;
    requestBody.temperature = 0;
  }

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify(requestBody),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`OpenAI API error: ${error}`);
  }

  const data = await response.json();
  
  // Handle GPT-5 responses which may have reasoning in a different format
  const content = data.choices?.[0]?.message?.content || "";
  
  // If content is empty but we have reasoning tokens, there might be an issue
  if (!content && data.usage?.completion_tokens_details?.reasoning_tokens > 0) {
    // GPT-5 might need more completion tokens for actual output after reasoning
    throw new Error("GPT-5 returned only reasoning tokens, no output. Try increasing max_completion_tokens or using a different model.");
  }
  
  if (!content) {
    throw new Error("No content in API response");
  }
  
  return content.trim();
}

async function getAnthropicCommand(apiKey: string): Promise<string> {
  // Map common model aliases to full Anthropic model names
  const modelMap: Record<string, string> = {
    "claude-opus-4-1": "claude-opus-4-1-20250805",
    "claude-opus-4": "claude-opus-4-20250514",
    "claude-sonnet-4": "claude-sonnet-4-20250514",
  };

  const fullModel = modelMap[model] || model;

  const response = await fetch("https://api.anthropic.com/v1/messages", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01",
    },
    body: JSON.stringify({
      model: fullModel,
      max_tokens: 200,
      temperature: 0,
      system: systemPrompt,
      messages: [
        {
          role: "user",
          content: prompt,
        },
      ],
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Anthropic API error: ${error}`);
  }

  const data = await response.json();
  return data.content[0].text.trim();
}

async function getApiKey(provider: "openai" | "anthropic"): Promise<string> {
  try {
    const result = await $`op read op://cli/${provider}/configs`.text();
    return result.trim();
  } catch (error) {
    throw new Error(
      `Failed to get ${provider.toUpperCase()} API key from 1Password. ` +
        `Ensure you have access to op://cli/${provider}/configs`
    );
  }
}

// Main execution
try {
  const provider = isAnthropic ? "anthropic" : "openai";
  const apiKey = await getApiKey(provider);

  const command = isAnthropic
    ? await getAnthropicCommand(apiKey)
    : await getOpenAICommand(apiKey);

  // Execute or output the command
  if (values.execute) {
    console.log(`$ ${command}`);
    const proc = Bun.spawn(["sh", "-c", command], {
      stdout: "inherit",
      stderr: "inherit",
      stdin: "inherit",
    });
    const exitCode = await proc.exited;
    process.exit(exitCode);
  } else {
    console.log(command);
  }
} catch (error) {
  console.error(`Error: ${error instanceof Error ? error.message : String(error)}`);
  process.exit(1);
}